### Summaries of CV trees
xtable(CV_summ,
caption = "Summaries of CV-tuned trees for predicting peak outbreak size across class size thresholds.",
label = "tab:peak_CV_Trees")
### Summaries of CV trees
xtable(CV_summ,
caption = "Summaries of CV-tuned trees for predicting CII across class size thresholds.",
label = "tab:CII_CV_Trees")
for(thresh in all_thresholds){
this_imps <- global_variable_importances[[thresh]]
print(xtable(this_imps))
}
### CV-RMSEs
xtable(global_GOF,
caption = "CV-RMSE for predicting logit-CII using selected trees across class size thresholds. *CV-RMSEs for trees chosen based on this metric are optimisitically biased.",
label = "tab:CII_GOF")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/School/Thesis/COVID_Network_Julia/Data Analysis/Peak Tree Fit/Peak Tree Fit - All Thresholds.R")
thresh = "20"
this_imps <- global_variable_importances[[thresh]]
print(xtable(this_imps))
thresh = "100"
this_imps <- global_variable_importances[[thresh]]
print(xtable(this_imps))
tree_sizes
global_variable_importances
this_thresh = "100"
#####################
### Fit Full Tree ###
#####################
fit_full <- data_tree %>%
filter(threshold == this_thresh) %>%
select(-threshold) %>%
rpart(logit ~ .,
data = .,
model = T,
control = rpart.control(cp = 0))
info_full <- fit_full$cptable
info_full
### Get MSE of root node
stump <- prune_size(fit_full, 0)
Y_hat <- predict(stump)
Y <- data_tree %>%
filter(threshold == this_thresh) %>%
select(logit)
stump_rmse <- sqrt(sum((Y - Y_hat)^2) / nrow(Y))
### Get minimum CV error and corresponding CP value
ind.best = which.min(info_full[, "xerror"])
CV.best = info_full[ind.best, "xerror"]
CP.best = info_full[ind.best, "CP"]
### Get the geometric mean of best CP with one above it
if (ind.best == 1) {
### If minimum CP is in row 1, store this value
CP.GM = CP.best
} else{
### If minimum CP is not in row 1, average this with the value from the
### row above it.
### Value from row above
CP.above = info_full[ind.best - 1, "CP"]
### (Geometric) average
CP.GM = sqrt(CP.best * CP.above)
}
### Fit minimum CV error tree
fit_min = prune(fit_full, cp = CP.best)
### Get the number of splits in the minimum CV error tree
ind_min <- which.min(info_full[, "xerror"])
splits_min <- info_full[ind_min, "nsplit"]
err_min <- sqrt(info_full[ind_min, "xerror"])
global_GOF[this_thresh, "CV-min"] <- err_min * stump_rmse
global_rel_GOF[this_thresh, "CV-min"] <- err_min
CV_summ[this_thresh, 3] <- splits_min # Number of splits
CV_summ[this_thresh, 4] <- err_min * stump_rmse # CV-min RMSE
### Get 1se rule CP value
err.min = info_full[ind.best, "xerror"]
se.min = info_full[ind.best, "xstd"]
threshold = err.min + se.min
ind.1se = min(which(info_full[1:ind.best, "xerror"] < threshold))
### Take geometric mean with superior row
CP.1se.raw = info_full[ind.1se, "CP"]
if (ind.1se == 1) {
### If best CP is in row 1, store this value
CP.1se = CP.1se.raw
} else{
### If best CP is not in row 1, average this with the value from the
### row above it.
### Value from row above
CP.above = info_full[ind.1se - 1, "CP"]
### (Geometric) average
CP.1se = sqrt(CP.1se.raw * CP.above)
}
### Prune the tree
fit_1se = prune(fit_full, cp = CP.1se)
### Get the number of splits in the 1se tree
ind_1se <- ind.1se
splits_1se <- info_full[ind_1se, "nsplit"]
err_1se <- sqrt(info_full[ind_1se, "xerror"])
global_GOF[this_thresh, "CV-1se"] <- err_1se * stump_rmse
global_rel_GOF[this_thresh, "CV-1se"] <- err_1se
CV_summ[this_thresh, 1] <- splits_1se # Number of splits
CV_summ[this_thresh, 2] <- err_1se * stump_rmse # CV-1se RMSE
info <- as_tibble(info_full) %>%
mutate(rxerror = sqrt(xerror))
### Plot errors for subtrees of the provided rpart object which do not exceed err
plot_good <- function(fit, err) {
this_info <- fit %>%
.$cptable %>%     # Extract the CP table
as_tibble() %>%   # Convert to a tibble for dplyr verbs
filter(xerror <= err) # Remove large errors
this_plot <- ggplot(this_info, aes(x = nsplit, y = xerror)) +
geom_line() + xlab("Number of Splits") + ylab("CV Error")
plot(this_plot)
}
CV_splits <- c(splits_min, splits_1se)
CV_errs <- c(err_min, err_1se)
plot_full <- ggplot(info, aes(x = nsplit, y = rxerror * stump_rmse)) +
geom_line() +
xlab("Number of Splits") + ylab("CV RMSE (logit scale)") +
ggtitle(paste0("Threshold = ", this_thresh)) +
theme(plot.title = element_text(hjust = 0.5)) +
geom_vline(xintercept = CV_splits) + ylim(c(0, NA))
plot(plot_full)
### Get CV errors for reasonably sized subtrees
tree_sizes <- c(10, 25, 50, 100, 200)
errs_small <- info %>%
filter(nsplit %in% tree_sizes) %>%
select(rxerror) %>%
unlist() %>%
as_tibble()
errs_small
if(this_thresh == "100") tree_sizes[1] = 9    # Hacky solution to no 10-split tree
errs_small <- info %>%
filter(nsplit %in% tree_sizes) %>%
select(rxerror) %>%
unlist() %>%
as_tibble()
colnames(errs_small) <- "rxerror"
errs_small %<>%
mutate(rabs_xerror = rxerror * stump_rmse,
)
errs_small
pred_names <- var_names[1:8]
### Get the variable importances from the provided rpart fit, and rescale
### so they sum to 1
get_var_imp <- function(fit){
raw_imps <- fit$variable.importance
raw_imps / sum(raw_imps)
}
### Store this_imps in row i of all_imps, and return updated all_imps
store_var_imps <- function(all_imps, i, this_imps){
for(pred in pred_names){
all_imps[i,pred] <- this_imps[pred]
}
return(all_imps)
}
### Build container for all variable improvements
all_imps <- array(0, dim = c(7, 8))
row.names(all_imps) <- c("CV-min", "CV-1se", "200", "100", "50", "25", "10")
colnames(all_imps) <- pred_names
### Make a list with all trees of interest
all_trees <- list(fit_min, fit_1se)
for(size in rev(tree_sizes)){
all_trees <- append(all_trees, list(prune_size(fit_full, size)))
}
all_trees
q = all_trees[[7]]
q
summary(q)
tree_sizes
source("D:/School/Thesis/COVID_Network_Julia/Data Analysis/Peak Tree Fit/Peak Tree Fit - All Thresholds.R")
thresh
thresh <- "100"
this_imps <- global_variable_importances[[thresh]]
print(xtable(this_imps))
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("D:/SFU Vault/STAT 300 - Spring 2022/Grade Script.R")
source("~/.active-rstudio-document", echo=TRUE)
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(dplyr)
library(magrittr)
library(ggplot2)
library(gridExtra)
library(purrr)
library(tibble)
library(ggfortify) # ggplot version of regression diagnostics
library(latex2exp) # Use latex for plot labels with the TeX() function
library(xtable)    # Create latex tables
num_students <- 17038
data <- read.csv("D:/School/Thesis/COVID_Network_Julia/Data/Output/Thinned/All_Outbreak_Sizes.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16675, 22715, 24041)
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
if(thresh == 20){
network_sizes[1]
} else if(thresh == 50){
network_sizes[2]
} else if(thresh == 100){
network_sizes[3]
} else{
stop("Invalid threshold level.")
}
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
for (i in 1:(ncol(data)-2)) {
levels(data[,i]) <- c("low", "med", "high")
}
get_formula <- function(resp_var, control_var, data, int = TRUE){
model_vars = data %>%
select(-!!resp_var, -!!control_var) %>%
names()
# First-order terms
(form_str <- paste(model_vars, collapse = " + "))
(form_str <- paste(control_var, form_str, sep = " + "))
(form_str <- paste(resp_var, form_str, sep = " ~ "))
# Second-order terms. Only include interactions with the control variable
if (int) {
(form_int_str <- paste(model_vars, control_var, sep = "*"))
(form_int_str <- paste(form_int_str, collapse = " + "))
(form_str <- paste(form_str, form_int_str, sep = " + "))
}
# Convert string to formula object
form = formula(form_str)
form
}
data$network_size <- sapply(data$threshold, thresh2size)
data_logit <- data %>%
mutate(prop = size / network_size) %>%
select(-size, -network_size)
var_names <- variable.names(data_logit)[1:9]
var_labels <- c(TeX("$\\rho_A$"), TeX("$\\rho_{I1}$"),
TeX("$\\theta_{I2}$"), TeX("$q_E$"), TeX("$q_A$"),
TeX("$q_{I1}$"), TeX("$q_{I2}$"), TeX("$q_{EA}$"),
TeX("$\\phi$")
)
base_boxplot <- ggplot(data_logit, aes(y = prop))
all_boxplots <- list(1:9)
for(i in 1:9){
this_plot <- base_boxplot +
geom_boxplot(aes_string(x = var_names[i])) +
xlab(var_labels[i]) + ylab("CII")
all_boxplots[[i]] <- this_plot
}
grid.arrange(grobs = all_boxplots, ncol=3)
plot(all_boxplots[[9]])
data_logit
num_students <- 17038
data <- read.csv("D:/School/Thesis/COVID_Network_Julia/Data/Output/Thinned/All_Outbreak_Peaks.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16675, 22715, 24041)
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
if(thresh == 20){
network_sizes[1]
} else if(thresh == 50){
network_sizes[2]
} else if(thresh == 100){
network_sizes[3]
} else{
stop("Invalid threshold level.")
}
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
for (i in 1:(ncol(data)-2)) {
levels(data[,i]) <- c("low", "med", "high")
}
get_formula <- function(resp_var, control_var, data, int = TRUE){
model_vars = data %>%
select(-!!resp_var, -!!control_var) %>%
names()
# First-order terms
(form_str <- paste(model_vars, collapse = " + "))
(form_str <- paste(control_var, form_str, sep = " + "))
(form_str <- paste(resp_var, form_str, sep = " ~ "))
# Second-order terms. Only include interactions with the control variable
if (int) {
(form_int_str <- paste(model_vars, control_var, sep = "*"))
(form_int_str <- paste(form_int_str, collapse = " + "))
(form_str <- paste(form_str, form_int_str, sep = " + "))
}
# Convert string to formula object
form = formula(form_str)
form
}
data$network_size <- sapply(data$threshold, thresh2size)
data_logit <- data %>%
mutate(prop = peak / network_size) %>%
select(-peak, -network_size)
hist_grid <- ggplot(data_logit, aes(x = prop)) +
geom_histogram() +
facet_wrap(~ threshold)
plot(hist_grid)
hist_grid <- ggplot(data_logit, aes(x = prop)) +
geom_histogram(bins = 500) +
facet_wrap(~ threshold)
plot(hist_grid)
num_students <- 25627
data <-
read.csv("D:/School/Thesis/COVID_Network_Julia/Data/Output/All_Outbreak_Sizes.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16866, 23660, 24752, 25627)
# ------------- Replace infinity character in threshold variable ------------- #
thresh <- data$threshold
inds_thresh <- thresh == unique(thresh)[4]
data[inds_thresh, "threshold"] <- "inf"
data$threshold = factor(data$threshold, levels = c("20", "50", "100", "inf"))
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
switch(thresh,
"20" = network_sizes[1],
"50" = network_sizes[2],
"100" = network_sizes[3],
"inf" = network_sizes[4],
stop("Invalid threshold level."))
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(dplyr)
library(magrittr)
library(ggplot2)
library(gridExtra)
library(purrr)
library(tibble)
library(ggfortify) # ggplot version of regression diagnostics
library(latex2exp) # Use latex for plot labels with the TeX() function
library(xtable)    # Create latex tables
num_students <- 25627
data <-
read.csv("D:/School/Thesis/COVID_Network_Julia/Data/Output/All_Outbreak_Sizes.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16866, 23660, 24752, 25627)
# ------------- Replace infinity character in threshold variable ------------- #
thresh <- data$threshold
inds_thresh <- thresh == unique(thresh)[4]
data[inds_thresh, "threshold"] <- "inf"
data$threshold = factor(data$threshold, levels = c("20", "50", "100", "inf"))
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
switch(thresh,
"20" = network_sizes[1],
"50" = network_sizes[2],
"100" = network_sizes[3],
"inf" = network_sizes[4],
stop("Invalid threshold level."))
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
for (i in 1:(ncol(data)-2)) {
levels(data[,i]) <- c("low", "med", "high")
}
get_formula <- function(resp_var, control_var, data, int = TRUE){
model_vars = data %>%
select(-!!resp_var, -!!control_var) %>%
names()
# First-order terms
(form_str <- paste(model_vars, collapse = " + "))
(form_str <- paste(control_var, form_str, sep = " + "))
(form_str <- paste(resp_var, form_str, sep = " ~ "))
# Second-order terms. Only include interactions with the control variable
if (int) {
(form_int_str <- paste(model_vars, control_var, sep = "*"))
(form_int_str <- paste(form_int_str, collapse = " + "))
(form_str <- paste(form_str, form_int_str, sep = " + "))
}
# Convert string to formula object
form = formula(form_str)
form
}
### Build vector of proportions
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes,
each = group_size)
data_logit_raw <- data %>%
arrange(threshold) %>%
mutate(network_size = all_network_sizes,
prop = size / network_size) %>%
select(-size, -network_size)
### Use logistic regression to model proportion who are ever infected
## Build formula for logistic regression
form = get_formula("prop", "threshold", data_logit_raw)
## Fit model with and without interactions
fit_glm_main <- glm(prop ~ ., family = binomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int <- glm(form, family = binomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_main_disper <- glm(prop ~ ., family = quasibinomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int_disper <- glm(form, family = quasibinomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
## Extract fitted proportions from models with interactions
p_hat_int = predict(fit_glm_int, type = "response")
p_hat_int_disper = predict(fit_glm_int_disper, type = "response")
### Estimate SD of Y in each group empirically
all_SDs_obs_raw = data_logit_raw %>%
add_column(p_hat_int = p_hat_int, p_hat_disp = p_hat_int_disper) %>%
group_by(across(infect_prop_A:threshold)) %>%
summarise(p_hat_obs = mean(prop), SD_obs = sd(prop),
p_hat_int = mean(p_hat_int), p_hat_disp = mean(p_hat_disp),
.groups="drop") %>%
mutate(SD_theo = sqrt(p_hat_int * (1 - p_hat_int)/sqrt(num_students)),
SD_disp = (p_hat_disp * (1 - p_hat_disp)/sqrt(num_students)))
all_SDs_obs <- filter(all_SDs_obs_raw,
!((threshold == "100") & (SD_obs > 0.15)))
### Remove extreme outlier from original data frame
row_remove <- all_SDs_obs_raw %>%
filter((threshold == "100") & (SD_obs > 0.15)) %>%
select(infect_prop_A:threshold)
data_logit <- data_logit_raw %>%
filter(!((infect_prop_A %in% row_remove[[1]]) &
(infect_prop_I1 %in% row_remove[[2]]) &
(infect_param_I2 %in% row_remove[[3]]) &
(advance_prob_E %in% row_remove[[4]]) &
(advance_prob_A %in% row_remove[[5]]) &
(advance_prob_I1 %in% row_remove[[6]]) &
(advance_prob_I2 %in% row_remove[[7]]) &
(E_to_A_prob %in% row_remove[[8]]) &
(threshold %in% row_remove[[9]])
))
# # This method also works, but is much slower
# pred_vars <- setdiff(names(data_logit_raw), c("prop"))
# check <- pbapply(data_logit_raw, 1, function(X){
#   all(X[pred_vars] == row_remove)
# })
# data_logit <- data_logit_raw[!check,]
K <- 10
set.seed(52501335)
logit <- function(x) log(x / (1-x))
### Container for CV-RMSPEs
### Indices are: model type (main vs 2-way vs 3-way), threshold, fold
all_RMSPEs <- array(0, dim = c(3, 4, K))
for(i in seq_along(all_thresholds)) {
this_thresh <- all_thresholds[i]
data_cv <- data_logit %>%
filter(threshold == this_thresh) %>%
select(-threshold)
n_cv <- nrow(data_cv)
fold_ids <- rep(1:K, times = n_cv %/% K) %>%
c(., seq_len(n_cv %% K)) %>%
sample(.)
for (k in seq_len(K)) {
print(paste0(i, ":", k))
train <- data_cv[fold_ids != k, ]
test <- data_cv[fold_ids == k, ]
logit_test <- logit(test$prop)
n_train <- nrow(train)
n_test <- nrow(test)
### Main effects model
fit <- glm(
prop ~ .,
data = train,
family = "binomial",
weights = rep(network_sizes[i], times = n_train)
)
pred <- predict(fit, newdata = test, type = "link")
RMSPE <- sqrt(mean((pred - logit_test) ^ 2))
all_RMSPEs[1, i, k] <- RMSPE
### Two-way interactions model
fit_int <- glm(
prop ~ .^2,
data = train,
family = "binomial",
weights = rep(network_sizes[i], times = n_train)
)
pred_int <- predict(fit_int, newdata = test, type = "link")
RMSPE_int <- sqrt(mean((pred_int - logit_test) ^ 2))
all_RMSPEs[2, i, k] <- RMSPE_int
### Three-way interactions model
fit_int <- glm(
prop ~ .^3,
data = train,
family = "binomial",
weights = rep(network_sizes[i], times = n_train)
)
pred_int <- predict(fit_int, newdata = test, type = "link")
RMSPE_int <- sqrt(mean((pred_int - logit_test) ^ 2))
all_RMSPEs[3, i, k] <- RMSPE_int
}
}
130.22+188.88
(RMSPE_means <- apply(all_RMSPEs, c(1,2), mean))
fit_int
?glm
q <- fit_int$coefficients
q
length(q)
28*4
1 + 16 + 112 + choose(8, 3)*8
save.image("D:/School/Thesis/COVID_Network_Julia/Data Analysis/Variable Importance/Small I1 Infectiousness/Importance - CII I1 Workspace.RData")
