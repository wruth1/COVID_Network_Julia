dev_imp_per_par <- dev_imps / n_pars
rel_imp_per_par <- dev_imp_per_par / max(dev_imp_per_par)
dev_imp_per_par
rel_imp_per_par
rel_dev_imps <- dev_imps / max(dev_imps)
dev_imps
rel_dev_imps
dev_imp_diffs <- diff(dev_imps)
dev_imp_diffs
rel_dev_imp_diffs <- dev_imp_diffs / max(dev_imp_diffs)
dev_imp_diffs <- diff(dev_imps)
rel_dev_imp_diffs <- dev_imp_diffs / max(dev_imp_diffs)
rel_dev_imp_diffs
par_diffs <- diff(n_pars)
par_diffs
all_dev_imp_diffs <- array(0,
dim = c(length(all_thresholds), length(n_pars)-1))
all_rel_dev_imp_diffs <- all_dev_imp_diffs
# Number of fitted parameters in each model
np0 <- 1
np1 <- 17
np2 <- 129
np3 <- 577
np4 <- 2257
n_pars <- c(np0, np1, np2, np3)
all_dev_imp_diffs <- array(0,
dim = c(length(all_thresholds), length(n_pars)-1))
all_rel_dev_imp_diffs <- all_dev_imp_diffs
all_dev_imps <- array(0,
dim = c(length(all_thresholds), length(n_pars)))
all_rel_dev_imps <- all_dev_imps
## Fit models
for (i in 1:length(all_thresholds)) {
print(paste(i, "of", length(all_thresholds)))
thresh = as.character(all_thresholds[i])
this_data <- filter(data_logit, threshold == thresh) %>%
select(-threshold)
this_weights <- rep(thresh2size(thresh), times = nrow(this_data))
# Fit models with increasing numbers of interactions
fit0 <- glm(prop ~ 1, this_data, family = quasibinomial(),
weights = this_weights)
fit1 <- glm(prop ~ ., this_data, family = quasibinomial(),
weights = this_weights)
fit2 <- glm(prop ~ . ^ 2,
this_data,
family = quasibinomial(),
weights = this_weights)
fit3 <- glm(prop ~ . ^ 3,
this_data,
family = quasibinomial(),
weights = this_weights)
fit4 <- glm(prop ~ . ^ 4,
this_data,
family = quasibinomial(),
weights = this_weights)
models <- list(fit0, fit1, fit2, fit3, fit4)
# models <- list(fit0, fit1, fit4)
# n_pars <- c(np0, np1, np4)
# Get deviance improvements
model_devs <- map_dbl(models, ~ .$deviance)
dev_imps <- map_dbl(model_devs, ~ model_devs[1] - .)
dev_imp_diffs <- diff(dev_imps)
rel_dev_imp_diffs <- dev_imp_diffs / max(dev_imp_diffs)
all_dev_imp_diffs[i,] <- dev_imp_diffs
all_rel_dev_imp_diffs[i,] <- rel_dev_imp_diffs
# par_diffs <- diff(n_pars)
dev_imp_per_par <- dev_imps / n_pars
rel_imp_per_par <- dev_imp_per_par / max(dev_imp_per_par)
all_dev_imps[i, ] <-  dev_imp_per_par
all_rel_dev_imps[i, ] <- rel_imp_per_par
}
dev_imp_diffs
all_dev_imp_diffs
# Number of fitted parameters in each model
np0 <- 1
np1 <- 17
np2 <- 129
np3 <- 577
np4 <- 2257
n_pars <- c(np0, np1, np2, np3, np4)
all_dev_imp_diffs <- array(0,
dim = c(length(all_thresholds), length(n_pars)-1))
all_rel_dev_imp_diffs <- all_dev_imp_diffs
all_dev_imps <- array(0,
dim = c(length(all_thresholds), length(n_pars)))
all_rel_dev_imps <- all_dev_imps
## Fit models
for (i in 1:length(all_thresholds)) {
print(paste(i, "of", length(all_thresholds)))
thresh = as.character(all_thresholds[i])
this_data <- filter(data_logit, threshold == thresh) %>%
select(-threshold)
this_weights <- rep(thresh2size(thresh), times = nrow(this_data))
# Fit models with increasing numbers of interactions
fit0 <- glm(prop ~ 1, this_data, family = quasibinomial(),
weights = this_weights)
fit1 <- glm(prop ~ ., this_data, family = quasibinomial(),
weights = this_weights)
fit2 <- glm(prop ~ . ^ 2,
this_data,
family = quasibinomial(),
weights = this_weights)
fit3 <- glm(prop ~ . ^ 3,
this_data,
family = quasibinomial(),
weights = this_weights)
fit4 <- glm(prop ~ . ^ 4,
this_data,
family = quasibinomial(),
weights = this_weights)
models <- list(fit0, fit1, fit2, fit3, fit4)
# models <- list(fit0, fit1, fit4)
# n_pars <- c(np0, np1, np4)
# Get deviance improvements
model_devs <- map_dbl(models, ~ .$deviance)
dev_imps <- map_dbl(model_devs, ~ model_devs[1] - .)
dev_imp_diffs <- diff(dev_imps)
rel_dev_imp_diffs <- dev_imp_diffs / max(dev_imp_diffs)
all_dev_imp_diffs[i,] <- dev_imp_diffs
all_rel_dev_imp_diffs[i,] <- rel_dev_imp_diffs
# par_diffs <- diff(n_pars)
dev_imp_per_par <- dev_imps / n_pars
rel_imp_per_par <- dev_imp_per_par / max(dev_imp_per_par)
all_dev_imps[i, ] <-  dev_imp_per_par
all_rel_dev_imps[i, ] <- rel_imp_per_par
}
all_rel_dev_imp_diffs
all_rel_dev_imps
all_thresholds
rownames(all_dev_imps) = all_thresholds
all_dev_imps
colnames(all_dev_imps) = c("Null", "Main", paste0(2:4, "-Way"))
all_dev_imps
rownames(all_dev_imp_diffs) = all_thresholds
colnames(all_dev_imp_diffs) = c("Main", paste0(2:4, "-Way"))
print(all_dev_imps)
print(rel_dev_imps)
print(all_dev_imp_diffs)
print(all_rel_dev_imp_diffs)
print(all_rel_dev_imps)
setwd("C:/Users/willi/Desktop/School/Thesis/COVID_Network_Julia/Data Analysis/Fit CII Model")
i=1
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(dplyr)
library(magrittr)
library(ggplot2)
library(gridExtra)
library(purrr)
library(tibble)
library(ggfortify) # ggplot version of regression diagnostics
library(latex2exp) # Use latex for plot labels with the TeX() function
library(xtable)    # Create latex tables
num_students <- 25627
data <- read.csv("C:/Users/willi/Desktop/School/Thesis/COVID_Network_Julia/Data/Output/All_Outbreak_Sizes.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16866, 23660, 24752, 25627)
# ------------- Replace infinity character in threshold variable ------------- #
thresh <- data$threshold
inds_thresh <- thresh == unique(thresh)[4]
data[inds_thresh, "threshold"] <- "inf"
data$threshold = factor(data$threshold, levels = c("20", "50", "100", "inf"))
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
switch(thresh,
"20" = network_sizes[1],
"50" = network_sizes[2],
"100" = network_sizes[3],
"inf" = network_sizes[4],
stop("Invalid threshold level."))
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
for (i in 1:(ncol(data)-2)) {
levels(data[,i]) <- c("low", "med", "high")
}
get_formula <- function(resp_var, control_var, data, int = TRUE){
model_vars = data %>%
select(-!!resp_var, -!!control_var) %>%
names()
# First-order terms
(form_str <- paste(model_vars, collapse = " + "))
(form_str <- paste(control_var, form_str, sep = " + "))
(form_str <- paste(resp_var, form_str, sep = " ~ "))
# Second-order terms. Only include interactions with the control variable
if (int) {
(form_int_str <- paste(model_vars, control_var, sep = "*"))
(form_int_str <- paste(form_int_str, collapse = " + "))
(form_str <- paste(form_str, form_int_str, sep = " + "))
}
# Convert string to formula object
form = formula(form_str)
form
}
### Build vector of proportions
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes,
each = group_size)
data_logit_raw <- data %>%
arrange(threshold) %>%
mutate(network_size = all_network_sizes,
prop = size / network_size) %>%
select(-size, -network_size)
### Use logistic regression to model proportion who are ever infected
## Build formula for logistic regression
form = get_formula("prop", "threshold", data_logit_raw)
## Fit model with and without interactions
fit_glm_main <- glm(prop ~ ., family = binomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int <- glm(form, family = binomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_main_disper <- glm(prop ~ ., family = quasibinomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int_disper <- glm(form, family = quasibinomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
## Extract fitted proportions from models with interactions
p_hat_int = predict(fit_glm_int, type = "response")
p_hat_int_disper = predict(fit_glm_int_disper, type = "response")
### Estimate SD of Y in each group empirically
all_SDs_obs_raw = data_logit_raw %>%
add_column(p_hat_int = p_hat_int, p_hat_disp = p_hat_int_disper) %>%
group_by(across(infect_prop_A:threshold)) %>%
summarise(p_hat_obs = mean(prop), SD_obs = sd(prop),
p_hat_int = mean(p_hat_int), p_hat_disp = mean(p_hat_disp),
.groups="drop") %>%
mutate(SD_theo = sqrt(p_hat_int * (1 - p_hat_int)/sqrt(num_students)),
SD_disp = (p_hat_disp * (1 - p_hat_disp)/sqrt(num_students)))
all_SDs_obs <- filter(all_SDs_obs_raw,
!((threshold == "100") & (SD_obs > 0.15)))
### Remove extreme outlier from original data frame
row_remove <- all_SDs_obs_raw %>%
filter((threshold == "100") & (SD_obs > 0.15)) %>%
select(infect_prop_A:threshold)
data_logit <- data_logit_raw %>%
filter(!((infect_prop_A %in% row_remove[[1]]) &
(infect_prop_I1 %in% row_remove[[2]]) &
(infect_param_I2 %in% row_remove[[3]]) &
(advance_prob_E %in% row_remove[[4]]) &
(advance_prob_A %in% row_remove[[5]]) &
(advance_prob_I1 %in% row_remove[[6]]) &
(advance_prob_I2 %in% row_remove[[7]]) &
(E_to_A_prob %in% row_remove[[8]]) &
(threshold %in% row_remove[[9]])
))
# # This method also works, but is much slower
# pred_vars <- setdiff(names(data_logit_raw), c("prop"))
# check <- pbapply(data_logit_raw, 1, function(X){
#   all(X[pred_vars] == row_remove)
# })
# data_logit <- data_logit_raw[!check,]
### Plot a histogram of CIIs across all simulations
CII_hist <- ggplot(data_logit, aes(x = prop)) +
geom_histogram(bins = 500) + xlab("CII")
# geom_histogram(aes(y = after_stat(density)), bins = 500)
plot(CII_hist)
### Subdivide by class size threshold
CII_hist_group <- CII_hist +
facet_wrap(~threshold) + xlim(0,1)
plot(CII_hist_group)
jpeg("C:\\Users\\willi\\sfuvault2\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_hist_homo.jpeg")
plot(CII_hist_group)
dev.off()
### Subdivide by class size threshold, and use free axis labels
CII_hist_group_free <- CII_hist +
facet_wrap(~threshold, scales = "free")
plot(CII_hist_group_free)
jpeg("C:\\Users\\willi\\sfuvault2\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_hist_hetero.jpeg")
plot(CII_hist_group_free)
dev.off()
### Build a data frame which contains number of remaining students after thresholding
data_hist <- data_logit
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes,
times = c(group_size, group_size, group_size - 10, group_size))
data_hist %<>% arrange(threshold) %>%
mutate(size = all_network_sizes,
prop = prop * size / num_students)
### Plot a histogram of CIIs across all simulations
CII_hist <- ggplot(data_hist, aes(x = prop)) +
geom_histogram(bins = 500) + xlab("CII")
# geom_histogram(aes(y = after_stat(density)), bins = 500)
plot(CII_hist)
### Subdivide by class size threshold
CII_hist_group <- CII_hist +
facet_wrap(~threshold)#, scales = "free")
plot(CII_hist_group)
### Subdivide by class size threshold, and use free axis labels
CII_hist_group_free <- CII_hist +
facet_wrap(~threshold, scales = "free")
plot(CII_hist_group_free)
pure_rep_plot <- ggplot(all_SDs_obs, aes(x = p_hat_obs, y = SD_obs^2)) +
geom_point(size = 0.25) + facet_wrap(~threshold, scales = "free") +
xlab("Average CII") + ylab("Observed Variance")
plot(pure_rep_plot)
### Super hacky way to get number of students remaining in each network. Use the threshold factor to index a list of network sizes.
pure_rep_plot_ref <- pure_rep_plot +
geom_line(aes(y = p_hat_obs*(1 - p_hat_obs)/network_sizes[threshold]),
color = "red")#, size=1.5)
plot(pure_rep_plot_ref)
jpeg("C:\\Users\\willi\\sfuvault2\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_disper_ref.jpeg")
plot(pure_rep_plot_ref)
dev.off()
### Fit all four models
### Note: Some gymnastics are being done with the formula object,
###       because a formula contains an environment, which must
###       match the context in which the formula is being used
###       (otherwise weird things can happen)
form_main <- data_logit %>%
select(-threshold) %>%
get_formula("prop", c(), ., int = F)
form_str <- paste(deparse(form_main), collapse = "")
all_thresholds <- unique(data_logit$threshold)
all_fits <- lapply(all_thresholds, function(thresh){
this_data <- filter(data_logit, threshold == !!thresh)
this_wts <- rep(thresh2size(as.character(thresh)), times = nrow(this_data))
fit = glm(formula(form_str), this_data, family = quasibinomial(),
weights = this_wts)
fit
})
# Number of fitted parameters in each model
np0 <- 1
np1 <- 17
np2 <- 129
np3 <- 577
np4 <- 2257
n_pars <- c(np0, np1, np2, np3, np4)
rbind(n_pars, all_dev_imps)
source("~/.active-rstudio-document", echo=TRUE)
num_students <- 25627
data <- read.csv("C:/Users/willi/Desktop/School/Thesis/COVID_Network_Julia/Data/Output/All_Outbreak_Sizes.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16866, 23660, 24752, 25627)
# ------------- Replace infinity character in threshold variable ------------- #
thresh <- data$threshold
inds_thresh <- thresh == unique(thresh)[4]
data[inds_thresh, "threshold"] <- "inf"
data$threshold = factor(data$threshold, levels = c("20", "50", "100", "inf"))
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
switch(thresh,
"20" = network_sizes[1],
"50" = network_sizes[2],
"100" = network_sizes[3],
"inf" = network_sizes[4],
stop("Invalid threshold level."))
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
for (i in 1:(ncol(data)-2)) {
levels(data[,i]) <- c("low", "med", "high")
}
get_formula <- function(resp_var, control_var, data, int = TRUE){
model_vars = data %>%
select(-!!resp_var, -!!control_var) %>%
names()
# First-order terms
(form_str <- paste(model_vars, collapse = " + "))
(form_str <- paste(control_var, form_str, sep = " + "))
(form_str <- paste(resp_var, form_str, sep = " ~ "))
# Second-order terms. Only include interactions with the control variable
if (int) {
(form_int_str <- paste(model_vars, control_var, sep = "*"))
(form_int_str <- paste(form_int_str, collapse = " + "))
(form_str <- paste(form_str, form_int_str, sep = " + "))
}
# Convert string to formula object
form = formula(form_str)
form
}
### Build vector of proportions
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes,
each = group_size)
data_logit_raw <- data %>%
arrange(threshold) %>%
mutate(network_size = all_network_sizes,
prop = size / network_size) %>%
select(-size, -network_size)
### Use logistic regression to model proportion who are ever infected
## Build formula for logistic regression
form = get_formula("prop", "threshold", data_logit_raw)
## Fit model with and without interactions
fit_glm_main <- glm(prop ~ ., family = binomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int <- glm(form, family = binomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_main_disper <- glm(prop ~ ., family = quasibinomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int_disper <- glm(form, family = quasibinomial(),
data = data_logit_raw, weights = rep(network_sizes, each = group_size))
## Extract fitted proportions from models with interactions
p_hat_int = predict(fit_glm_int, type = "response")
p_hat_int_disper = predict(fit_glm_int_disper, type = "response")
### Estimate SD of Y in each group empirically
all_SDs_obs_raw = data_logit_raw %>%
add_column(p_hat_int = p_hat_int, p_hat_disp = p_hat_int_disper) %>%
group_by(across(infect_prop_A:threshold)) %>%
summarise(p_hat_obs = mean(prop), SD_obs = sd(prop),
p_hat_int = mean(p_hat_int), p_hat_disp = mean(p_hat_disp),
.groups="drop") %>%
mutate(SD_theo = sqrt(p_hat_int * (1 - p_hat_int)/sqrt(num_students)),
SD_disp = (p_hat_disp * (1 - p_hat_disp)/sqrt(num_students)))
all_SDs_obs <- filter(all_SDs_obs_raw,
!((threshold == "100") & (SD_obs > 0.15)))
data <- data_logit %>%
filter(threshold=="20")
weights <- thresh2size("20")
data <- data_logit %>%
filter(threshold=="20") %>%
select(-threshold)
weights <- thresh2size("20")
fit <- glm(prop ~ ., data = data, family = quasibinomial(),
weights = weights)
?glm
weights
length(data)
nrow(data)
weights <- rep(thresh2size("20"), times = nrow(data))
fit <- glm(prop ~ ., data = data, family = quasibinomial(),
weights = weights)
mu <- predict(fit, type = "response")
y
y <- data$prop
y
mu
plot(mu, y)
n <- thresh2size(thresh)
thresh <- "20"
n <- thresh2size(thresh)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
num_students <- 25627
data <- read.csv("C:/Users/willi/Desktop/School/Thesis/COVID_Network_Julia/Data/Output/All_Outbreak_Sizes.csv")
num_trials = nrow(data)
# Number of students remaining in the network for each threshold level
network_sizes <- c(16866, 23660, 24752, 25627)
# ------------- Replace infinity character in threshold variable ------------- #
thresh <- data$threshold
inds_thresh <- thresh == unique(thresh)[4]
data[inds_thresh, "threshold"] <- "inf"
data$threshold = factor(data$threshold, levels = c("20", "50", "100", "inf"))
all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
switch(thresh,
"20" = network_sizes[1],
"50" = network_sizes[2],
"100" = network_sizes[3],
"inf" = network_sizes[4],
stop("Invalid threshold level."))
}
for (i in 1:(ncol(data)-1)) {
data[, i] <- factor(data[, i])
}
for (i in 1:(ncol(data)-2)) {
levels(data[,i]) <- c("low", "med", "high")
}
get_formula <- function(resp_var, control_var, data, int = TRUE){
model_vars = data %>%
select(-!!resp_var, -!!control_var) %>%
names()
# First-order terms
(form_str <- paste(model_vars, collapse = " + "))
(form_str <- paste(control_var, form_str, sep = " + "))
(form_str <- paste(resp_var, form_str, sep = " ~ "))
# Second-order terms. Only include interactions with the control variable
if (int) {
(form_int_str <- paste(model_vars, control_var, sep = "*"))
(form_int_str <- paste(form_int_str, collapse = " + "))
(form_str <- paste(form_str, form_int_str, sep = " + "))
}
# Convert string to formula object
form = formula(form_str)
form
}
### Build vector of proportions
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes,
each = group_size)
data_logit_raw <- data %>%
arrange(threshold) %>%
mutate(network_size = all_network_sizes,
prop = size / network_size) %>%
select(-size, -network_size)
### Use logistic regression to model proportion who are ever infected
## Build formula for logistic regression
form = get_formula("prop", "threshold", data_logit_raw)
### Estimate SD of Y in each group empirically
all_SDs_obs_raw = data_logit_raw %>%
add_column(p_hat_int = p_hat_int, p_hat_disp = p_hat_int_disper) %>%
group_by(across(infect_prop_A:threshold)) %>%
summarise(p_hat_obs = mean(prop), SD_obs = sd(prop),
p_hat_int = mean(p_hat_int), p_hat_disp = mean(p_hat_disp),
.groups="drop") %>%
mutate(SD_theo = sqrt(p_hat_int * (1 - p_hat_int)/sqrt(num_students)),
SD_disp = (p_hat_disp * (1 - p_hat_disp)/sqrt(num_students)))
all_SDs_obs <- filter(all_SDs_obs_raw,
!((threshold == "100") & (SD_obs > 0.15)))
devs1 <- map2_dbl(y, mu, ~get_dev1(.y, .x, n))
devs1
devs2 <- map2_dbl(y, mu, ~get_dev2(.y, .x, n))
source("~/.active-rstudio-document", echo=TRUE)
fitted_dev
dev_guess1
dev_guess2
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
