---
title: "Fit CII Model"
author: "William Ruth"
output: 
  pdf_document
---


```{r packages, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)


library(knitr)
library(dplyr)
library(magrittr)
library(ggplot2)
library(gridExtra)
library(purrr)
library(tibble)
library(ggfortify) # ggplot version of regression diagnostics
library(latex2exp) # Use latex for plot labels with the TeX() function
library(xtable)    # Create latex tables
```


```{r setup, include=FALSE, cache=TRUE}
num_students <- 25627

data <-
  read.csv("D:/School/Thesis/COVID_Network_Julia/Data/Output/All_Outbreak_Sizes.csv")


num_trials = nrow(data)

# Number of students remaining in the network for each threshold level
network_sizes <- c(16866, 23660, 24752, 25627)

# ------------- Replace infinity character in threshold variable ------------- #
thresh <- data$threshold
inds_thresh <- thresh == unique(thresh)[4]
data[inds_thresh, "threshold"] <- "inf"
data$threshold = factor(data$threshold, levels = c("20", "50", "100", "inf"))

all_thresholds <- unique(data$threshold)
thresh2size <- function(thresh){
  switch(thresh,
    "20" = network_sizes[1],
    "50" = network_sizes[2],
    "100" = network_sizes[3],
    "inf" = network_sizes[4],
    stop("Invalid threshold level."))
}

for (i in 1:(ncol(data)-1)) {
  data[, i] <- factor(data[, i])
}

for (i in 1:(ncol(data)-2)) {
  levels(data[,i]) <- c("low", "med", "high")
}



get_formula <- function(resp_var, control_var, data, int = TRUE){
  model_vars = data %>%
    select(-!!resp_var, -!!control_var) %>%
    names()
  
  # First-order terms
  (form_str <- paste(model_vars, collapse = " + "))
  (form_str <- paste(control_var, form_str, sep = " + "))
  (form_str <- paste(resp_var, form_str, sep = " ~ "))
  
  # Second-order terms. Only include interactions with the control variable
  if (int) {
    (form_int_str <- paste(model_vars, control_var, sep = "*"))
    (form_int_str <- paste(form_int_str, collapse = " + "))
    (form_str <- paste(form_str, form_int_str, sep = " + "))
  }
  
  # Convert string to formula object
  form = formula(form_str)
  
  form
}


### Build vector of proportions
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes, 
  each = group_size)
data_logit_raw <- data %>% 
  arrange(threshold) %>% 
  mutate(network_size = all_network_sizes, 
    prop = size / network_size) %>% 
  select(-size, -network_size)


### Use logistic regression to model proportion who are ever infected

## Build formula for logistic regression
form = get_formula("prop", "threshold", data_logit_raw)


## Fit model with and without interactions
fit_glm_main <- glm(prop ~ ., family = binomial(), 
  data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int <- glm(form, family = binomial(), 
  data = data_logit_raw, weights = rep(network_sizes, each = group_size))

fit_glm_main_disper <- glm(prop ~ ., family = quasibinomial(), 
  data = data_logit_raw, weights = rep(network_sizes, each = group_size))
fit_glm_int_disper <- glm(form, family = quasibinomial(), 
  data = data_logit_raw, weights = rep(network_sizes, each = group_size))

## Extract fitted proportions from models with interactions
p_hat_int = predict(fit_glm_int, type = "response")
p_hat_int_disper = predict(fit_glm_int_disper, type = "response")


### Estimate SD of Y in each group empirically
all_SDs_obs_raw = data_logit_raw %>%
  add_column(p_hat_int = p_hat_int, p_hat_disp = p_hat_int_disper) %>% 
  group_by(across(infect_prop_A:threshold)) %>%
  summarise(p_hat_obs = mean(prop), SD_obs = sd(prop),
    p_hat_int = mean(p_hat_int), p_hat_disp = mean(p_hat_disp),
    .groups="drop") %>%
  mutate(SD_theo = sqrt(p_hat_int * (1 - p_hat_int)/sqrt(num_students)), 
    SD_disp = (p_hat_disp * (1 - p_hat_disp)/sqrt(num_students))) 

all_SDs_obs <- filter(all_SDs_obs_raw,
  !((threshold == "100") & (SD_obs > 0.15)))

```

# Analysis #

In this document, we fit quasi-binomial GLMs in each of the four class size threshold groups to predict CII using the epidemiological parameters of our simulation. Note that there is some ambiguity in the definition of CII since the population size varies as we change the class size threshold. Unless stated otherwise, we always define CII relative to the number of students remaining in the network after thresholding, rather than relative to the total number of students enrolled (although in the unthresholded case these numbers coincide). *This is made even more complicated by the fact that we remove all but the largest connected component. All network sizes reported in this document are for the largest remaining connected component after thresholding.*

The extreme outlier in the threshold = 100 group has been removed.

```{r remove_outlier, include = F}
### Remove extreme outlier from original data frame
row_remove <- all_SDs_obs_raw %>% 
  filter((threshold == "100") & (SD_obs > 0.15)) %>% 
  select(infect_prop_A:threshold)

data_logit <- data_logit_raw %>% 
  filter(!((infect_prop_A %in% row_remove[[1]]) &
      (infect_prop_I1 %in% row_remove[[2]]) &
      (infect_param_I2 %in% row_remove[[3]]) &
      (advance_prob_E %in% row_remove[[4]]) &
      (advance_prob_A %in% row_remove[[5]]) &
      (advance_prob_I1 %in% row_remove[[6]]) &
      (advance_prob_I2 %in% row_remove[[7]]) &
      (E_to_A_prob %in% row_remove[[8]]) &
      (threshold %in% row_remove[[9]])
    ))
  
# # This method also works, but is much slower
# pred_vars <- setdiff(names(data_logit_raw), c("prop"))
# check <- pbapply(data_logit_raw, 1, function(X){
#   all(X[pred_vars] == row_remove)
# })
# data_logit <- data_logit_raw[!check,]
```


Before doing any model fitting, we plot a histogram of the CII, both globally and separately by class size threshold, where the counts are of individual runs of our simulation ($N =$ `r formatC(num_trials, format = "f", digits = 0)`).

```{r global_CII_hist, fig.cap="\\label{fig:global_hist}Histogram of CII."}

### Plot a histogram of CIIs across all simulations
CII_hist <- ggplot(data_logit, aes(x = prop)) +
  geom_histogram(bins = 500) + xlab("CII")
  # geom_histogram(aes(y = after_stat(density)), bins = 500)
plot(CII_hist)
```


```{r group_CII_hist, fig.cap="\\label{fig:group_hist}Histograms of CII for each class size threshold with uniform axis scaling."}
### Subdivide by class size threshold
CII_hist_group <- CII_hist + 
  facet_wrap(~threshold) + xlim(0,1)
plot(CII_hist_group)

jpeg("D:\\SFU Vault\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_hist_homo.jpeg")
plot(CII_hist_group)
dev.off()
```

```{r group_CII_hist_free, fig.cap="\\label{fig:group_hist_free}Histograms of CII for each class size threshold with heteogeneous axis scaling."}
### Subdivide by class size threshold, and use free axis labels
CII_hist_group_free <- CII_hist + 
  facet_wrap(~threshold, scales = "free")
plot(CII_hist_group_free)

# possible_vals_raw <- seq(0, 1, by = 1/num_students)
# possible_vals <- data.frame(val = possible_vals_raw)
# inf_vals <- possible_vals %>% 
#   filter(q > 0.88, q < 0.94) %>% 
#   unlist()
# 
# inf_props <- data_logit %>% 
#   filter(threshold == "inf") %>% 
#   select(prop) %>% 
#   unlist()
# 
# obs_inf_vals <- inf_props %>% 
#   unique() %>% 
#   sort()
# 
# obs_inf_vals %in% inf_vals
# 
# num_unique_vals <- function(X){
#   X %>% 
#     unique() %>% 
#     unlist() %>% 
#     length()
# }
# 
# data_logit %>% 
#   group_by(threshold) %>% 
#   summarise(num_unique_vals(prop))

jpeg("D:\\SFU Vault\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_hist_hetero.jpeg")
plot(CII_hist_group_free)
dev.off()

# jpeg("D:\\SFU Vault\\CornellStudy\\Tex\\Plots\\Weird_CII_Histograms.jpeg")
# plot(CII_hist_group_free)
# dev.off()
```


Next, we produce the same plots, but with CII computed relative to the total number of students, rather than the number of students remaining in the network after thresholding.


```{r small_CII, include=FALSE}
### Build a data frame which contains number of remaining students after thresholding
data_hist <- data_logit
group_size <- num_trials/4
all_network_sizes <- rep(network_sizes, 
  times = c(group_size, group_size, group_size - 10, group_size))
data_hist %<>% arrange(threshold) %>% 
  mutate(size = all_network_sizes, 
    prop = prop * size / num_students) 

```

```{r global_small_CII_hist, fig.cap="\\label{fig:global_hist_small}Histogram of CII relative to total number of students."}

### Plot a histogram of CIIs across all simulations
CII_hist <- ggplot(data_hist, aes(x = prop)) +
  geom_histogram(bins = 500) + xlab("CII")
  # geom_histogram(aes(y = after_stat(density)), bins = 500)
plot(CII_hist)
```


```{r group_small_CII_hist, fig.cap="\\label{fig:group_hist_small}Histograms of CII relative to total number of students for each class size threshold with uniform axis scaling."}
### Subdivide by class size threshold
CII_hist_group <- CII_hist + 
  facet_wrap(~threshold)#, scales = "free")
plot(CII_hist_group)
```

```{r group__smallCII_hist_free, fig.cap="\\label{fig:group_hist_free_small}Histograms of CII relative to total number of students for each class size threshold with heteogeneous axis scaling."}
### Subdivide by class size threshold, and use free axis labels
CII_hist_group_free <- CII_hist + 
  facet_wrap(~threshold, scales = "free")
plot(CII_hist_group_free)
```


There are clearly different levels of variability between the different threshold groups. This suggests that we should use an extended quasi-likelihood model with different overdispersion parameters in each group.

The structure of our simulation study includes pure replication within each parameter setting (specifically, we have 10 replicates for each parameter combination). This allows us to investigate the pure replication variability, which informs what we expect to see when we fit our GLM. The following plot gives average CII vs sample variance for each parameter combination (**Footnote: the average and variance are computed over the 10 replicates within a single parameter combination**).

```{r var_fun_plot}
pure_rep_plot <- ggplot(all_SDs_obs, aes(x = p_hat_obs, y = SD_obs^2)) +
  geom_point(size = 0.25) + facet_wrap(~threshold, scales = "free") +
  xlab("Average CII") + ylab("Observed Variance")
plot(pure_rep_plot)
```

Next, we reproduce these plots but also add a reference line at the variance which is predicted by the binomial distribution (i.e. at $p(1-p)/N$, where $N$ is the number of students remaining in the network).

```{r var_fun_ref_plot}
### Super hacky way to get number of students remaining in each network. Use the threshold factor to index a list of network sizes.
pure_rep_plot_ref <- pure_rep_plot +
  geom_line(aes(y = p_hat_obs*(1 - p_hat_obs)/network_sizes[threshold]),
    color = "red")#, size=1.5)
plot(pure_rep_plot_ref)

jpeg("D:\\SFU Vault\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_disper_ref.jpeg")
plot(pure_rep_plot_ref)
dev.off()
```

Our data clearly exhibit overdispersion relative to the predictions of a binomial model. 


## Investigate Interactions


Next, we fit a sequence of models with the first four levels of interaction terms, as well as the null model with only an intercept. We summarize these fits with a few comparisons.

```{r Fit_Interactions, cache=T, include=F}
# Number of fitted parameters in each model
np0 <- 1
np1 <- 17
np2 <- 129
np3 <- 577
np4 <- 2257

n_pars <- c(np0, np1, np2, np3, np4)

all_dev_imp_diffs <- array(0, 
  dim = c(length(all_thresholds), length(n_pars)-1))
rownames(all_dev_imp_diffs) = all_thresholds
colnames(all_dev_imp_diffs) = c("Main", paste0(2:4, "-Way"))
all_rel_dev_imp_diffs <- all_dev_imp_diffs


all_dev_imps <- array(0, 
  dim = c(length(all_thresholds), length(n_pars)))
rownames(all_dev_imps) = all_thresholds
colnames(all_dev_imps) = c("Null", "Main", paste0(2:4, "-Way"))
all_rel_dev_imps <- all_dev_imps



## Fit models
for (i in 1:length(all_thresholds)) {
  print(paste(i, "of", length(all_thresholds)))
  thresh = as.character(all_thresholds[i])
  
  this_data <- filter(data_logit, threshold == thresh) %>%
    select(-threshold)
  this_weights <- rep(thresh2size(thresh), times = nrow(this_data))
  
  # Fit models with increasing numbers of interactions
  fit0 <- glm(prop ~ 1, this_data, family = quasibinomial(),
    weights = this_weights)
  fit1 <- glm(prop ~ ., this_data, family = quasibinomial(),
    weights = this_weights)
  fit2 <- glm(prop ~ . ^ 2,
    this_data,
    family = quasibinomial(),
    weights = this_weights)
  fit3 <- glm(prop ~ . ^ 3,
    this_data,
    family = quasibinomial(),
    weights = this_weights)
  fit4 <- glm(prop ~ . ^ 4,
    this_data,
    family = quasibinomial(),
    weights = this_weights)
  
  models <- list(fit0, fit1, fit2, fit3, fit4)
  # models <- list(fit0, fit1, fit4)
  # n_pars <- c(np0, np1, np4)
  
  # Get deviance improvements
  model_devs <- map_dbl(models, ~ .$deviance)
  dev_imps <- map_dbl(model_devs, ~ model_devs[1] - .)
  
  dev_imp_diffs <- diff(dev_imps)
  rel_dev_imp_diffs <- dev_imp_diffs / max(dev_imp_diffs)
  
  all_dev_imp_diffs[i,] <- dev_imp_diffs
  all_rel_dev_imp_diffs[i,] <- rel_dev_imp_diffs
  
  # par_diffs <- diff(n_pars)
  
  dev_imp_per_par <- dev_imps / n_pars
  rel_imp_per_par <- dev_imp_per_par / max(dev_imp_per_par)
  
  all_dev_imps[i, ] <-  dev_imp_per_par
  all_rel_dev_imps[i, ] <- rel_imp_per_par
}
```
First, we give the deviance improvement of each fit relative to the null model divided by the number of fitted parameters in that model.

```{r Deviance_Improvements}
all_dev_imps <- rbind(n_pars, all_dev_imps)
rownames(all_dev_imps)[1] <- "Num Pars"
all_dev_imps = all_dev_imps[,-1]

print(all_dev_imps)
```

Next, we give the relative improvement per parameter within each class size threshold.

```{r Relative_Deviance_Improvements}
all_rel_dev_imps <- rbind(n_pars, all_rel_dev_imps)
rownames(all_rel_dev_imps)[1] <- "Num Pars"
all_rel_dev_imps = all_rel_dev_imps[,-1]

print(all_rel_dev_imps)
```

We also report the improvement at each step over the next-largest model.

```{r Stepwise_Deviance_Improvements}
print(all_dev_imp_diffs)
```

And the corresponding relative improvements within each class size threshold.

```{r Relative_Stepwise_Deviance_Improvements}
print(all_rel_dev_imp_diffs)
```

We now proceed to fit the models to which we have been alluding. First, the four models, with one for each level of class size threshold.

```{r fit_models}

### Fit all four models
### Note: Some gymnastics are being done with the formula object,
###       because a formula contains an environment, which must
###       match the context in which the formula is being used
###       (otherwise weird things can happen)
form_main <- data_logit %>% 
  select(-threshold) %>% 
  get_formula("prop", c(), ., int = F)
form_str <- paste(deparse(form_main), collapse = "")
all_thresholds <- unique(data_logit$threshold)
all_fits <- lapply(all_thresholds, function(thresh){
  this_data <- filter(data_logit, threshold == !!thresh)
  this_wts <- rep(thresh2size(as.character(thresh)), times = nrow(this_data))
  fit = glm(formula(form_str), this_data, family = quasibinomial(), 
  weights = this_wts)
  
  fit
})

```

## Diagnostics ##

We now investigate some of the standard diagnostic plots for evaluating GLM fits. Figures \ref{fig:dev_resid} and \ref{fig:pear_resid} give the deviance and Pearson residuals respectively for each class size threshold.

```{r Plot_Dev_Residuals, fig.cap="\\label{fig:dev_resid}Deviance residuals for each class size threshold."}
### Need to do this from scratch. The plot.lm function isn't well documented so I'm not certain what it's doing, and the ggplot version won't let me put all four plots in a grid.

### Extract info from fitted models
all_fitted_values <- all_fits %>% map(predict, type = "response") %>% unlist()
all_dev_resids <- all_fits %>% map(residuals, type="deviance") %>%   unlist()
all_pear_resids <- all_fits %>% map(residuals, type="pearson") %>%   unlist()

### Get list of class size thresholds
threshold_list <- data_logit$threshold

### Construct data frame for residual analysis
data_resid <- tibble(threshold = threshold_list,
  fitted = all_fitted_values, dev = all_dev_resids,
  pear = all_pear_resids, obs = data_logit$prop)

### Construct plot of residuals vs fitted values
plot_dev_resid <- ggplot(data_resid, aes(x = fitted, y = dev)) +
  geom_point(size = 0.25) + facet_wrap(~threshold, scales = "free") +
  xlab("Fitted CII") + ylab("Deviance Residual")
plot_dev_resid
```

```{r Plot_Pearson_Residuals, , fig.cap="\\label{fig:pear_resid}Pearson residuals for each class size threshold."}
plot_pear_resid <- ggplot(data_resid, aes(x = fitted, y = pear)) +
  geom_point(size = 0.25) + facet_wrap(~threshold, scales = "free") +
  xlab("Fitted CII") + ylab("Pearson Residual")
plot_pear_resid
```


```{r Plot_Obs_vs_Fit, fig.cap="\\label{fig:obs_vs_fit}Observed CII vs fitted values."}

### Construct plot of observed vs fitted values
plot_obs_fit <- ggplot(data_resid, aes(x = fitted, y = obs)) +
  geom_point(size = 0.1) + facet_wrap(~threshold, scales = "free") +
  xlab("Fitted CII") + ylab("Observed CII") +
  geom_abline(slope = 1, intercept = 0, size = 1.2, colour = "red")
plot_obs_fit
```


# Results #

We now report some summaries. 

## Deviance Changes ##

To start, we extract the deviance improvement provided by each variable when added to a model already containing the other predictors.

```{r group_deviances, cache=TRUE}
### Deviances make more sense if they are divided by the overdispersion parameter
all_dispers <- sapply(all_fits, function(fit){
  summary(fit)$dispersion
})
names(all_dispers) <- all_thresholds


### Extract deviances
all_deviances <- sapply(all_fits, function(fit){
  info_raw <- drop1(fit)
  info <- info_raw$Deviance
  
  deltas <- info[-1] - info[1]
})

all_resid_deviances <- map_dbl(all_fits, ~.$deviance)
all_deviances = rbind(all_deviances, all_resid_deviances)

all_deviances_raw <- all_deviances #Unscaled by disper. par.

for(i in 1:ncol(all_deviances)){
  all_deviances[,i] = all_deviances[,i] / all_dispers[i]
}

# For future reference, get the names of the non-threshold predictors
pred_names <- data_logit %>% 
  select(-threshold, -prop) %>%
  colnames()

colnames(all_deviances) <- all_thresholds
rownames(all_deviances) <- c(pred_names, "Residual")

kable(formatC(all_deviances, format = "E", digits = 2),
  caption="\\label{tab:group_devs}Deviance improvements within each class size threshold.")

xtable(formatC(all_deviances, format = "E", digits = 2),
  caption = "Deviance increase caused by omitting each variable from a model containing all others. Models are fit separately for each class size threshold.", align = "ccccc", label = "tab:dev_CII")
```

For reference, we give the relative change in deviance compared to the largest in each group.

```{r col_rel_devs, echo=F}
rel_devs <- apply(all_deviances, 2, function(X) X/max(X))
kable(formatC(rel_devs, format = "G", digits = 2),
  caption = "\\label{tab:rel_devs}Relative deviance improvements within each class size threshold.")

xtable(formatC(rel_devs, format = "G", digits = 2),
  caption = "Relative deviance increases within each class size threshold.", align = "ccccc", label = "tab:rel_dev_CII")
```

We also rank the predictors within each group in decreasing order of deviance improvement.

```{r col_dev_ranks, echo=F}
# Remove residual deviance from ranking
ranks <- apply(rel_devs[-nrow(rel_devs),], 2, function(X) rank(-X))
row.names(ranks) <- pred_names
kable(ranks, caption="\\label{tab:dev_ranks}Ranked deviance improvements within each class size threshold. 1 has the greatest improvement and 8 has the least.")

xtable(ranks,
  caption = "Deviance increase ranks within each class size threshold. 1 has the greatest incease and 8 has the smallest.", label = "tab:dev_CII_ranks", align = "ccccc", digits = 0)

```


## Overdispersion Parameter ##

Next, we present the fitted overdispersion parameter from each group.

```{r group_dispers, echo=F}


formatC(all_dispers, format = "f", digits = 0)
```

## Rescaled Overdispersion Plots ##

```{r var_fun_scaled_plot}
### Super hacky way to get number of students remaining in each network and overdispersion parameter. Use the threshold factor to index a list of network sizes.
data_ref_scaled = all_SDs_obs
data_ref_scaled$overdisp = all_dispers[data_ref_scaled$threshold]

pure_rep_plot_ref_scaled <- ggplot(data_ref_scaled, aes(x = p_hat_obs, y = SD_obs^2)) +
  geom_point(size = 0.25) + facet_wrap(~threshold, scales = "free") +
  xlab("Average CII") + ylab("Observed Variance") + 
  geom_line(aes(y = p_hat_obs*(1 - p_hat_obs)/network_sizes[threshold]),
    color = "red", size = 1.2) +
  geom_line(aes(y = p_hat_obs*(1 - p_hat_obs) * overdisp[threshold] /network_sizes[threshold]),
    color = "blue", size = 1.2, lty = 2)
plot(pure_rep_plot_ref_scaled)

jpeg("D:\\SFU Vault\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_Disper_Ref_Scaled.jpeg")
plot(pure_rep_plot_ref_scaled)
dev.off()
```

## Global Model ##

**Caution: The analyses in this section are all of proportions relative to the total number of students, rather than the number in the largest remaining connected component as in the rest of this document.**

For reference, we repeat the above analysis on the ordinary quasi-likelihood model. That is, we retain the interaction terms for the mean model, but use a single global overdispersion parameter.

```{r fit_global, include=FALSE}
fit <- glm(form, data = data_logit, family = quasibinomial(),
  weights = rep(num_students, times = nrow(data_logit)))
```


The deviance changes for excluding each variable individually from our model (while retaining all others) are as follows.

```{r dev_global, cache=TRUE, echo=FALSE}
info_raw <- drop1(fit)
info <- info_raw$Deviance
deltas <- info[-1] - info[1]

names(deltas) <- data_logit %>% 
  select(-threshold, -prop) %>%
  colnames()

formatC(deltas, format = "E", digits = 2)
```

Similarly, the relative deviance improvements are:

```{r rel_dev_global, include=FALSE}
formatC(deltas/max(deltas), format = "G", digits = 2)
```

```{r disper_global, include=FALSE}
phi_hat <- summary(fit)$dispersion
```


Finally, the fitted global overdispersion parameter is `r round(phi_hat, 0)`, which is the mean of the individual group models' overdispersion parameters.




## Marginal Behaviour of Each Predictor ##

The following figure gives a sequence of boxplots for the CII in our simulation. Each plot corresponds to a single predictor, and each box contains all simulation runs with that level of the predictor.

```{r Boxplot_Grid}
var_names <- variable.names(data_logit)[1:9]
var_labels <- c(TeX("$\\rho_A$"), TeX("$\\rho_{I1}$"),
  TeX("$\\theta_{I2}$"), TeX("$q_E$"), TeX("$q_A$"),
  TeX("$q_{I1}$"), TeX("$q_{I2}$"), TeX("$q_{EA}$"), 
  TeX("$\\phi$")
  )

base_boxplot <- ggplot(data_logit, aes(y = prop)) + ylim(0, 1)
all_boxplots <- list(1:9)
for(i in 1:9){
  this_plot <- base_boxplot +
    geom_boxplot(aes_string(x = var_names[i])) +
    xlab(var_labels[i]) + ylab("CII")
  all_boxplots[[i]] <- this_plot
}
grid.arrange(grobs = all_boxplots, ncol=3)
jpeg("D:\\SFU Vault\\CornellStudy\\Tex\\Plots\\CII_Analysis\\CII_Boxplots.jpeg")
grid.arrange(grobs = all_boxplots, ncol=3)
dev.off()
```


The threshold variable clearly has the greatest association with CII, so we reproduce that boxplot **with greater resolution**.

```{r Thresh_Boxplot}
all_boxplots[[9]]
```

## Interaction Boxplots ##

We next construct boxplots to investigate the interactions between sepidemiological parameters and our control strategy, class size threshold. Specifically, for each epidemiological parameter, we construct three sets of four boxplots, with the four thresholds each being represented within all levels of the epi parameter.

```{r Interaction_Boxplots}
base_inter_boxplots <- ggplot(data_logit, aes(y = prop))
all_inter_boxplots <- list(1:8)

for(i in 1:8){
  this_plot <- base_inter_boxplots +
    geom_boxplot(aes(x = threshold)) +
    facet_wrap(var_names[i]) +
    ylab("CII") + ggtitle(var_labels[i]) +
    theme(plot.title = element_text(hjust = 0.5))#, size = 20))
  
  plot(this_plot + theme(plot.title = element_text(size = 20)))
  
  all_inter_boxplots[[i]] <- this_plot
}

# grid.arrange(grobs = all_inter_boxplots, qwncol=3)

```



# Discussion #

In Tables \ref{tab:group_devs}-\ref{tab:dev_ranks}, we see that the infectiousness parameter for the symptomatic group has the largest deviance improvement in every model. Recall that the infectiousness parameter for the symptomatic group gives the absolute proportionality constant for infection probability (proportional to 1 / the square root of the class size). However, the parameter for the presymptomatic and asymptomatic groups reflect their relative infectiousness compared to the symptomatic group. Thus, increasing or decreasing the infectiousness parameter for the symptomatic group changes the infection probability for all infectious compartments, while the parameters for presymptomatic and asymptomatic only affect their own compartment.

Based on the relative deviance contributions across variables given in Tables \ref{tab:rel_devs} and \ref{tab:dev_ranks}, we see that the infectiousness of symptomatic individuals is most strongly associated with CII. As discussed above, this parameter must be interpreted carefully in our model, so we 

The behaviour of the threshold = 20 group is qualitatively different from the other threshold levels. In Figures \ref{fig:group_hist} and \ref{fig:group_hist_free}, we see that the CIIs clump around 0 with a long right tail when threshold is 20, while the other groups have their mass concentrated above 0.5. 

